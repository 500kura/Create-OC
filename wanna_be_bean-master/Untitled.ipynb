{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n",
      "Number of faces detected: 1\n",
      "Number of faces detected: 1\n",
      "Number of faces detected: 1\n",
      "Number of faces detected: 1\n",
      "Number of faces detected: 1\n",
      "Number of faces detected: 1\n",
      "Number of faces detected: 1\n",
      "Number of faces detected: 1\n",
      "Number of faces detected: 1\n",
      "Mr. Beanをロードしました.\n",
      "Number of faces detected: 1\n",
      "Number of faces detected: 1\n",
      "Number of faces detected: 3\n",
      "Number of faces detected: 2\n",
      "Number of faces detected: 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7710de142806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    200\u001b[0m   \u001b[0mbe_bean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_bean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./images/WIN_20190625_15_14_38_Pro.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m   \u001b[0mbe_bean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_bean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./images/WIN_20190625_15_19_33_Pro.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m   \u001b[0mbe_bean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_bean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./images/WIN_20190625_15_21_13_Pro.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m   \u001b[0mbe_bean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_bean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./images/WIN_20190625_15_24_21_Pro.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m   \u001b[1;31m# be_bean.to_bean('./images/thor.jpg')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-7710de142806>\u001b[0m in \u001b[0;36mto_bean\u001b[1;34m(self, image_path)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mto_bean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_faces_from_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;31m# base_imageに合成していく\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-7710de142806>\u001b[0m in \u001b[0;36mload_faces_from_image\u001b[1;34m(self, image_path)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m     54\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     image = cv2.resize(image, (image.shape[1] * self.SCALE_FACTOR,\n\u001b[0m\u001b[0;32m     56\u001b[0m                                image.shape[0] * self.SCALE_FACTOR))\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "PREDICTOR_PATH = './shape_predictor_68_face_landmarks.dat'\n",
    "PREDICTOR = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n",
    "class NoFaces(Exception):\n",
    "    pass\n",
    "\n",
    "class Face:\n",
    "  def __init__(self, image, rect):\n",
    "    self.image = image\n",
    "    self.landmarks = numpy.matrix(\n",
    "      [[p.x, p.y] for p in PREDICTOR(image, rect).parts()]\n",
    "    )\n",
    "\n",
    "class BeBean:\n",
    "  SCALE_FACTOR = 1\n",
    "  FEATHER_AMOUNT = 11\n",
    "\n",
    "  # 特徴点のうちそれぞれの部位を表している配列のインデックス\n",
    "  FACE_POINTS = list(range(17, 68))\n",
    "  MOUTH_POINTS = list(range(48, 61))\n",
    "  RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "  LEFT_BROW_POINTS = list(range(22, 27))\n",
    "  RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "  LEFT_EYE_POINTS = list(range(42, 48))\n",
    "  NOSE_POINTS = list(range(27, 35))\n",
    "  JAW_POINTS = list(range(0, 17))\n",
    "\n",
    "  ALIGN_POINTS = (LEFT_BROW_POINTS + RIGHT_EYE_POINTS + LEFT_EYE_POINTS + RIGHT_BROW_POINTS +\n",
    "    NOSE_POINTS + MOUTH_POINTS)\n",
    "\n",
    "  # オーバーレイする特徴点\n",
    "  OVERLAY_POINTS = [LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS,\n",
    "    NOSE_POINTS + MOUTH_POINTS]\n",
    "\n",
    "  COLOR_CORRECT_BLUR_FRAC = 0.7\n",
    "\n",
    "  def __init__(self, before_after = True):\n",
    "    self.detector = dlib.get_frontal_face_detector()\n",
    "    self._load_beans()\n",
    "    self.before_after = before_after\n",
    "\n",
    "  def load_faces_from_image(self, image_path):\n",
    "    \"\"\"\n",
    "      画像パスから画像オブジェクトとその画像から抽出した特徴点を読み込む。\n",
    "      ※ 画像内に顔が1つないし複数検出された場合も、返すので正確には「特徴点配列」の配列を返す\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (image.shape[1] * self.SCALE_FACTOR,\n",
    "                               image.shape[0] * self.SCALE_FACTOR))\n",
    "\n",
    "    rects = self.detector(image, 1)\n",
    "\n",
    "    if len(rects) == 0:\n",
    "      raise NoFaces\n",
    "    else:\n",
    "      print(\"Number of faces detected: {}\".format(len(rects)))\n",
    "\n",
    "    faces = [Face(image, rect) for rect in rects]\n",
    "    return image, faces\n",
    "\n",
    "  def transformation_from_points(self, t_points, o_points):\n",
    "    \"\"\"\n",
    "      特徴点から回転やスケールを調整する。\n",
    "      t_points: (target points) 対象の特徴点(入力画像)\n",
    "      o_points: (origin points) 合成元の特徴点(つまりビーン)\n",
    "    \"\"\"\n",
    "\n",
    "    t_points = t_points.astype(numpy.float64)\n",
    "    o_points = o_points.astype(numpy.float64)\n",
    "\n",
    "    t_mean = numpy.mean(t_points, axis = 0)\n",
    "    o_mean = numpy.mean(o_points, axis = 0)\n",
    "\n",
    "    t_points -= t_mean\n",
    "    o_points -= o_mean\n",
    "\n",
    "    t_std = numpy.std(t_points)\n",
    "    o_std = numpy.std(o_points)\n",
    "\n",
    "    t_points -= t_std\n",
    "    o_points -= o_std\n",
    "\n",
    "    # 行列を特異分解しているらしい\n",
    "    # https://qiita.com/kyoro1/items/4df11e933e737703d549\n",
    "    U, S, Vt = numpy.linalg.svd(t_points.T * o_points)\n",
    "    R = (U * Vt).T\n",
    "\n",
    "    return numpy.vstack(\n",
    "      [numpy.hstack((( o_std / t_std ) * R, o_mean.T - ( o_std / t_std ) * R * t_mean.T )),\n",
    "      numpy.matrix([ 0., 0., 1. ])]\n",
    "    )\n",
    "\n",
    "  def get_face_mask(self, face):\n",
    "    image = numpy.zeros(face.image.shape[:2], dtype = numpy.float64)\n",
    "    for group in self.OVERLAY_POINTS:\n",
    "      self._draw_convex_hull(image, face.landmarks[group], color = 1)\n",
    "\n",
    "    image = numpy.array([ image, image, image ]).transpose((1, 2, 0))\n",
    "    image = (cv2.GaussianBlur(image, (self.FEATHER_AMOUNT, self.FEATHER_AMOUNT), 0) > 0) * 1.0\n",
    "    image = cv2.GaussianBlur(image, (self.FEATHER_AMOUNT, self.FEATHER_AMOUNT), 0)\n",
    "\n",
    "    return image\n",
    "\n",
    "  def warp_image(self, image, M, dshape):\n",
    "    output_image = numpy.zeros(dshape, dtype = image.dtype)\n",
    "    cv2.warpAffine(\n",
    "      image,\n",
    "      M[:2],\n",
    "      (dshape[1], dshape[0]),\n",
    "      dst = output_image, borderMode = cv2.BORDER_TRANSPARENT, flags = cv2.WARP_INVERSE_MAP\n",
    "    )\n",
    "    return output_image\n",
    "\n",
    "  def correct_colors(self, t_image, o_image, t_landmarks):\n",
    "    \"\"\"\n",
    "      対象の画像に合わせて、色を補正する\n",
    "    \"\"\"\n",
    "    blur_amount = self.COLOR_CORRECT_BLUR_FRAC * numpy.linalg.norm(\n",
    "      numpy.mean(t_landmarks[self.LEFT_EYE_POINTS], axis = 0) -\n",
    "      numpy.mean(t_landmarks[self.RIGHT_EYE_POINTS], axis = 0)\n",
    "    )\n",
    "    blur_amount = int(blur_amount)\n",
    "\n",
    "    if blur_amount % 2 == 0: blur_amount += 1\n",
    "\n",
    "    t_blur = cv2.GaussianBlur(t_image, (blur_amount, blur_amount), 0)\n",
    "    o_blur = cv2.GaussianBlur(o_image, (blur_amount, blur_amount), 0)\n",
    "\n",
    "    # ゼロ除算を避ける　\n",
    "    o_blur += (128 * (o_blur <= 1.0)).astype(o_blur.dtype)\n",
    "\n",
    "    return (o_image.astype(numpy.float64) * t_blur.astype(numpy.float64) / o_blur.astype(numpy.float64))\n",
    "\n",
    "  def to_bean(self, image_path):\n",
    "    original, faces = self.load_faces_from_image(image_path)\n",
    "\n",
    "    # base_imageに合成していく\n",
    "    base_image = original.copy()\n",
    "\n",
    "    for face in faces:\n",
    "      bean = self._get_bean_similar_to(face)\n",
    "      bean_mask = self.get_face_mask(bean)\n",
    "\n",
    "      M = self.transformation_from_points(\n",
    "        face.landmarks[self.ALIGN_POINTS],\n",
    "        bean.landmarks[self.ALIGN_POINTS]\n",
    "      )\n",
    "\n",
    "      warped_bean_mask = self.warp_image(bean_mask, M, base_image.shape)\n",
    "      combined_mask = numpy.max(\n",
    "        [self.get_face_mask(face), warped_bean_mask], axis = 0\n",
    "      )\n",
    "\n",
    "      warped_image = self.warp_image(bean.image, M, base_image.shape)\n",
    "      warped_corrected_image = self.correct_colors(base_image, warped_image, face.landmarks)\n",
    "      base_image = base_image * (1.0 - combined_mask) + warped_corrected_image * combined_mask\n",
    "\n",
    "    path, ext = os.path.splitext( os.path.basename(image_path) )\n",
    "    cv2.imwrite('outputs/output_' + path + ext, base_image)\n",
    "\n",
    "    if self.before_after is True:\n",
    "      before_after = numpy.concatenate((original, base_image), axis = 1)\n",
    "      cv2.imwrite('before_after/' + path + ext, before_after)\n",
    "\n",
    "  def _draw_convex_hull(self, image, points, color):\n",
    "    \"指定したイメージの領域を塗りつぶす\"\n",
    "\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(image, points, color = color)\n",
    "\n",
    "  def _load_beans(self):\n",
    "    \"Mr. ビーンの画像をロードして、顔(特徴点など)を検出しておく\"\n",
    "\n",
    "    self.beans = []\n",
    "    for image_path in glob.glob(os.path.join('beans', '*.jpg')):\n",
    "      image, bean_face = self.load_faces_from_image(image_path)\n",
    "      self.beans.append(bean_face[0])\n",
    "    print('Mr. Beanをロードしました.')\n",
    "\n",
    "  def _get_bean_similar_to(self, face):\n",
    "    \"特徴点の差分距離が小さいMr.ビーンを返す\"\n",
    "\n",
    "    get_distances = numpy.vectorize(lambda bean: numpy.linalg.norm(face.landmarks - bean.landmarks))\n",
    "\n",
    "    distances = get_distances(self.beans)\n",
    "    return self.beans[distances.argmin()]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  be_bean = BeBean()\n",
    "  be_bean.to_bean('./images/kanna.jpg')\n",
    "  be_bean.to_bean('./images/kikuti.jpg')\n",
    "  be_bean.to_bean('./images/avengers.jpg')\n",
    "  be_bean.to_bean('./images/WIN_20190625_15_14_38_Pro.jpg')\n",
    "  be_bean.to_bean('./images/WIN_20190625_15_19_33_Pro.jpg')\n",
    "  be_bean.to_bean('./images/WIN_20190625_15_21_13_Pro.jpg')\n",
    "  be_bean.to_bean('./images/WIN_20190625_15_24_21_Pro.jpg')\n",
    "  # be_bean.to_bean('./images/thor.jpg')\n",
    "  # be_bean.to_bean('./images/x-men.jpg')\n",
    "  # be_bean.to_bean('./images/iron-man.jpg')\n",
    "  # be_bean.to_bean('./images/captain.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
