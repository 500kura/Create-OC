{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "認識結果\n",
      "(x,y)=(94,88)  高さ：77  幅：77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "\n",
    "import cv2\n",
    "\n",
    "# 認識対象ファイルの指定\n",
    "image_path = \"target/Lenna.png\"\n",
    "# 認識対象ファイルの読み込み\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# グレースケールに変換\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 顔認識用特徴量のファイル指定\n",
    "cascade_path = \"haarcascades/haarcascade_frontalface_alt.xml\"\n",
    "# カスケード分類器の特徴量を取得する\n",
    "cascade = cv2.CascadeClassifier(cascade_path)\n",
    "# 顔認識の実行\n",
    "facerecog = cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=1, minSize=(1, 1))\n",
    "\n",
    "#　認識した顔を囲む矩形の色を指定。ここでは白。\n",
    "color = (255, 255, 255) \n",
    "\n",
    "if len(facerecog) > 0:\n",
    "\n",
    "\n",
    "    # 認識した顔全てを矩形で囲む\n",
    "    for rect in facerecog:\n",
    "\n",
    "        # 認識結果を表示\n",
    "        print (\"認識結果\")\n",
    "        print (\"(x,y)=(\" + str(rect[0]) + \",\" + str(rect[1])+ \")\" + \\\n",
    "            \"  高さ：\"+str(rect[2]) + \\\n",
    "            \"  幅：\"+str(rect[3]))\n",
    "\n",
    "        cv2.rectangle(image, tuple(rect[0:2]),tuple(rect[0:2]+rect[2:4]), color, thickness=2)\n",
    "\n",
    "# 認識結果の出力\n",
    "cv2.imwrite(\"result/Lenna_result.png\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, height, width):\n",
    "\n",
    "    # 元々のサイズを取得\n",
    "    org_height, org_width = image.shape[:2]\n",
    "\n",
    "    # 大きい方のサイズに合わせて縮小\n",
    "    if float(height)/org_height > float(width)/org_width:\n",
    "        ratio = float(height)/org_height\n",
    "    else:\n",
    "        ratio = float(width)/org_width\n",
    "\n",
    "    # リサイズ\n",
    "    resized = cv2.resize(image,(int(org_height*ratio),int(org_width*ratio)))\n",
    "\n",
    "    return resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    ol_imgae_path = \"target/warai_otoko.png\"    \n",
    "    ol_image = cv2.imread(ol_imgae_path,cv2.IMREAD_UNCHANGED)   # アルファチャンネル(透過)も読みこむようにIMREAD_INCHANGEDを指定\n",
    "\n",
    "    # リサイズ\n",
    "    resized_image = resize_image(ol_image, 100, 100)\n",
    "\n",
    "    # 認識結果の出力\n",
    "    cv2.imwrite(\"result/warai_otoko_result.png\", resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def overlayOnPart(src_image, overlay_image, posX, posY):\n",
    "\n",
    "    # オーバレイ画像のサイズを取得\n",
    "    ol_height, ol_width = overlay_image.shape[:2]\n",
    "\n",
    "    # OpenCVの画像データをPILに変換\n",
    "    #　BGRAからRGBAへ変換\n",
    "    src_image_RGBA = cv2.cvtColor(src_image, cv2.COLOR_BGR2RGB)\n",
    "    overlay_image_RGBA = cv2.cvtColor(overlay_image, cv2.COLOR_BGRA2RGBA)\n",
    "\n",
    "    #　PILに変換\n",
    "    src_image_PIL=Image.fromarray(src_image_RGBA)\n",
    "    overlay_image_PIL=Image.fromarray(overlay_image_RGBA)\n",
    "\n",
    "    # 合成のため、RGBAモードに変更\n",
    "    src_image_PIL = src_image_PIL.convert('RGBA')\n",
    "    overlay_image_PIL = overlay_image_PIL.convert('RGBA')\n",
    "\n",
    "    # 同じ大きさの透過キャンパスを用意\n",
    "    tmp = Image.new('RGBA', src_image_PIL.size, (255, 255,255, 0))\n",
    "    # 用意したキャンパスに上書き\n",
    "    tmp.paste(overlay_image_PIL, (posX, posY), overlay_image_PIL)\n",
    "    # オリジナルとキャンパスを合成して保存\n",
    "    result = Image.alpha_composite(src_image_PIL, tmp)\n",
    "\n",
    "    return  cv2.cvtColor(np.asarray(result), cv2.COLOR_RGBA2BGRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "認識結果\n",
      "(x,y)=(94,88)  高さ：77  幅：77\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def overlay_face():\n",
    "\n",
    "    # 認識対象ファイルの読み込み\n",
    "    image_path = \"target/Lenna.png\"\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # 上書きする画像の読み込み\n",
    "    ol_imgae_path = \"target/warai_otoko.png\"    \n",
    "    ol_image = cv2.imread(ol_imgae_path,cv2.IMREAD_UNCHANGED)   # アルファチャンネル(透過)も読みこむようにIMREAD_INCHANGEDを指定\n",
    "\n",
    "    # グレースケールに変換\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 顔認識用特徴量のファイル指定\n",
    "    cascade_path = \"haarcascades/haarcascade_frontalface_alt.xml\"\n",
    "    # カスケード分類器の特徴量を取得する\n",
    "    cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "    # 顔認識の実行\n",
    "    facerecog = cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=1, minSize=(1, 1))\n",
    "\n",
    "\n",
    "    if len(facerecog) > 0:\n",
    "\n",
    "\n",
    "        # 認識した顔全てに画像を上書きする\n",
    "        for rect in facerecog:\n",
    "\n",
    "            # 認識結果を表示\n",
    "            print (\"認識結果\")\n",
    "            print (\"(x,y)=(\" + str(rect[0]) + \",\" + str(rect[1])+ \")\" + \\\n",
    "                \"  高さ：\"+str(rect[2]) + \\\n",
    "                \"  幅：\"+str(rect[3]))\n",
    "\n",
    "            # 認識範囲にあわせて画像をリサイズ\n",
    "            resized_ol_image = resize_image(ol_image, rect[2], rect[3])\n",
    "\n",
    "            # 上書きした画像の作成\n",
    "            image = overlayOnPart(image, resized_ol_image, rect[0], rect[1])\n",
    "\n",
    "    # 認識結果の出力\n",
    "    cv2.imwrite(\"result/Lenna_result.png\", image)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    overlay_face()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
